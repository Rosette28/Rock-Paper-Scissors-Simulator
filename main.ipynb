{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a7f2f8",
   "metadata": {},
   "source": [
    "## Rock Paper Scissor Game Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50789f11",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da3b9f",
   "metadata": {},
   "source": [
    "| Strategy Name                            | Explanation                                                                  | Type                       |\n",
    "| ---------------------------------------- | ---------------------------------------------------------------------------- | -------------------------- |\n",
    "| **s_random**                             | Chooses R, P, or S uniformly at random.                                      | Random                     |\n",
    "| **s_constant_R**                         | Always chooses Rock.                                                         | Static              |\n",
    "| **s_constant_P**                         | Always chooses Paper.                                                        | Static              |\n",
    "| **s_constant_S**                         | Always chooses Scissors.                                                     | Static              |\n",
    "| **s_constant(choice)**                   | Always chooses the move(s) specified in `choice`.                            | Static              |\n",
    "| **s_probabilities(probabilities)**       | Chooses R, P, or S according to given probabilities `[Pr, Pp, Ps]`.          | Random/Biased              |\n",
    "| **s_uniform_between(choices)**           | Chooses randomly between the given subset of moves.                          | Random                     |\n",
    "| **s_special_choice(special_choice, p)**  | Chooses `special_choice` with probability `p`, others with `(1-p)/2`.        | Biased                     |\n",
    "| **s_main_choice(main_choice)**           | Chooses `main_choice` with high probability (0.8).                           | Biased                     |\n",
    "| **s_neglected_choice(neglected_choice)** | Chooses `neglected_choice` with low probability (0.2).                       | Biased                     |\n",
    "| **s_mimic_opponent**                     | Chooses whatever the opponent played in the previous round.                  | Reactive                   |\n",
    "| **s_last_move_wp_p(context, p)**         | Chooses the player’s last move with probability `p`, otherwise switches.     | Reactive                   |\n",
    "| **s_tend_to_repeat**                     | Favors repeating the player’s last move.                                     | Reactive                   |\n",
    "| **s_tend_to_change**                     | Favors switching from the player’s last move.                                | Reactive                   |\n",
    "| **s_never_repeat**                       | Never chooses the player’s last move; picks from the other two.              | Reactive                   |\n",
    "| **s_result_dependent**                   | Repeats last move if it won the previous round, otherwise changes.           | Reactive                   |\n",
    "| **s_human_like**                         | Biased probabilities: R>P>S, adjusts slightly based on last move and result. | Hybrid (Biased + Reactive) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038363b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcef02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d01c422",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7350127",
   "metadata": {},
   "outputs": [],
   "source": [
    "RPS = ['R', 'P', 'S'] # R = Rock, P = Paper, S = scissor\n",
    "#last_move = [rd.choice(list(RPS)), rd.choice(list(RPS))]\n",
    "#last_winner = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd906cf",
   "metadata": {},
   "source": [
    "# Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a1d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints an error message and terminates the program\n",
    "def print_error_and_exit(message = \"something wrong happened\"):\n",
    "    print(message)\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f993cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function checks if it's parameter is a subset of RPS\n",
    "# If yes it returns True, \n",
    "# Otherwise it prints that the parameter passed is an invalid choice and exits from the program\n",
    "\n",
    "def check_if_valid_choice(to_check):\n",
    "    set_to_check = set(to_check)\n",
    "    if set_to_check.issubset(RPS):\n",
    "        return True\n",
    "    print_error_and_exit(\"invalid choice passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43e5b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function checks if it's parameter is a valid probability\n",
    "# If yes it returns True, \n",
    "# Otherwise it prints that the parameter passed is an invalid choice and exits from the program\n",
    "\n",
    "def check_if_valid_probability(to_check):\n",
    "    if isinstance(to_check, (int, float)):\n",
    "        to_check = [to_check]\n",
    "    for p in to_check:\n",
    "        if not (0 <= p <= 1):\n",
    "            print_error_and_exit(\"invalid probability passed\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cd11cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decide winner between two moves\n",
    "def get_winner(move1, move2):\n",
    "    if move1 == move2:\n",
    "        return 0\n",
    "    elif (move1 == 'R' and move2 == 'S') or \\\n",
    "         (move1 == 'S' and move2 == 'P') or \\\n",
    "         (move1 == 'P' and move2 == 'R'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1dbbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(probs):\n",
    "    total = sum(probs)\n",
    "    if total == 0:\n",
    "        print_error_and_exit(\"sum of probabilities cannot be zero\")\n",
    "    return [p / total for p in probs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c008a6e",
   "metadata": {},
   "source": [
    "# Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4931ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose R with probability P0\n",
    "# Choose P with probability P1\n",
    "# Choose S with probability P2\n",
    "\n",
    "def s_probabilities(probabilities):\n",
    "    if len(probabilities) != 3:\n",
    "        print_error_and_exit(\"wrong number of probabilities\")\n",
    "    check_if_valid_probability(probabilities)\n",
    "    probabilities = normalize(probabilities)\n",
    "    return rd.choices(RPS, weights=probabilities, k=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d29ce130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose randomly between the subset of choices passed\n",
    "def s_uniform_between(choices):\n",
    "    check_if_valid_choice(choices)\n",
    "    return rd.choice(list(choices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d54ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Strategy: \n",
    "# Choose each of the three options (R,P,S) with probability 1/3\n",
    "def s_random(context=None):\n",
    "    return s_uniform_between(RPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17046663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant Strategy:\n",
    "# Choose the same thing all the time (passed as a parameter)\n",
    "# And I made other 3 functions - one for each choice\n",
    "\n",
    "def s_constant(choice):\n",
    "    return s_uniform_between(choice)\n",
    "\n",
    "def s_constant_R(context=None): return 'R'\n",
    "def s_constant_P(context=None): return 'P'\n",
    "def s_constant_S(context=None): return 'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63da01bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#special choice strategy: \n",
    "#choose 1 thing with probability p,\n",
    "#choose the others with probability (1-p)/2\n",
    "#derived strategies: main_choice (high p), neglected_choice (low p)\n",
    "\n",
    "def s_special_choice(special_choice, p):\n",
    "    check_if_valid_probability(p)\n",
    "    check_if_valid_choice(special_choice)\n",
    "    probs = [0, 0, 0]\n",
    "    idx = RPS.index(special_choice)\n",
    "    probs[idx] = p\n",
    "    others = (1 - p) / 2\n",
    "    for i in range(3):\n",
    "        if i != idx:\n",
    "            probs[i] = others\n",
    "    return s_probabilities(probs)\n",
    "\n",
    "def s_main_choice(main_choice):\n",
    "    return s_special_choice(main_choice, 0.8)\n",
    "\n",
    "def s_neglected_choice(neglected_choice):\n",
    "    return s_special_choice(neglected_choice, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c4f5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose what the opponent chose last move\n",
    "def s_mimic_opponent(context):\n",
    "    return context[\"last_move_opponent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08c10dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose like you did previous round with probability p\n",
    "# Three strategies derived from it are:\n",
    "# 1. change your choice with high probability (tend to not repeat)\n",
    "# 2. change your choice with low probability (tend to stick to last choice)\n",
    "# 3. never repeat: never choose what you chose last round\n",
    "\n",
    "def s_last_move_wp_p(context, p):\n",
    "    return s_special_choice(context[\"last_move_self\"], p)\n",
    "\n",
    "def s_tend_to_change(context):\n",
    "    return s_neglected_choice(context[\"last_move_self\"])\n",
    "\n",
    "def s_tend_to_repeat(context):\n",
    "    return s_main_choice(context[\"last_move_self\"])\n",
    "\n",
    "def s_never_repeat(context):\n",
    "    return s_uniform_between(set(RPS).difference(context[\"last_move_self\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e33ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tend to repeat last move if it led to winning the round\n",
    "# otherwise tend to choose something else\n",
    "\n",
    "def s_result_dependent(context):\n",
    "    if context[\"last_winner\"] == context[\"player_n\"]:\n",
    "        return s_tend_to_repeat(context)\n",
    "    return s_tend_to_change(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8883f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Human like\" strategy (what I think)\n",
    "# choose R more often than P, and choose P more often than S\n",
    "# tend to repeat last choice when it led to winning,\n",
    "# but tend to change it if it led to losing\n",
    "# anyway relatively low probability to repeat last move (even when winning)\n",
    "\n",
    "def s_human_like(context):\n",
    "    probabilities = np.array([0.5, 0.3, 0.2])  # R>P>S\n",
    "    move_to_index = {'R': 0, 'P': 1, 'S': 2}\n",
    "    last = context[\"last_move_self\"]\n",
    "    idx = move_to_index[last]\n",
    "    probabilities[idx] /= 4\n",
    "    if context[\"last_winner\"] == 0:\n",
    "        probabilities[idx] *= 2\n",
    "    probabilities = probabilities / probabilities.sum()\n",
    "    return s_probabilities(probabilities)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56f6e82",
   "metadata": {},
   "source": [
    "# Play Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c940e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(strategy1, strategy2, n=100):\n",
    "    global last_move, last_winner\n",
    "    last_move = [rd.choice(RPS), rd.choice(RPS)]\n",
    "    last_winner = 0\n",
    "\n",
    "    wins = [0, 0]\n",
    "    ties = 0\n",
    "\n",
    "    for _ in range(n):\n",
    "        ctx1 = {\n",
    "            \"last_move_self\": last_move[0],\n",
    "            \"last_move_opponent\": last_move[1],\n",
    "            \"last_winner\": last_winner,\n",
    "            \"player_n\": 1\n",
    "        }\n",
    "        ctx2 = {\n",
    "            \"last_move_self\": last_move[1],\n",
    "            \"last_move_opponent\": last_move[0],\n",
    "            \"last_winner\": last_winner,\n",
    "            \"player_n\": 2\n",
    "        }\n",
    "\n",
    "        # Get moves\n",
    "        try:\n",
    "            move1 = strategy1(ctx1)\n",
    "        except TypeError:\n",
    "            move1 = strategy1()\n",
    "        try:\n",
    "            move2 = strategy2(ctx2)\n",
    "        except TypeError:\n",
    "            move2 = strategy2()\n",
    "\n",
    "        if move1 not in RPS or move2 not in RPS:\n",
    "            print_error_and_exit(f\"Invalid move: {move1}, {move2}\")\n",
    "\n",
    "        # Decide winner\n",
    "        winner = get_winner(move1, move2)\n",
    "        if winner == 1:\n",
    "            wins[0] += 1\n",
    "            last_winner = 1\n",
    "        elif winner == 2:\n",
    "            wins[1] += 1\n",
    "            last_winner = 2\n",
    "        else:\n",
    "            ties += 1\n",
    "            last_winner = 0\n",
    "\n",
    "        last_move = [move1, move2]\n",
    "\n",
    "    print(\"\\n--- Game Results ---\")\n",
    "    print(f\"Player 1 wins: {wins[0]} ({wins[0]/n*100:.1f}%)\")\n",
    "    print(f\"Player 2 wins: {wins[1]} ({wins[1]/n*100:.1f}%)\")\n",
    "    print(f\"Ties: {ties} ({ties/n*100:.1f}%)\")\n",
    "\n",
    "    return wins, ties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f09aa",
   "metadata": {},
   "source": [
    "# Example Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a1aa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 3283 (32.8%)\n",
      "Player 2 wins: 3389 (33.9%)\n",
      "Ties: 3328 (33.3%)\n",
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 3369 (33.7%)\n",
      "Player 2 wins: 3323 (33.2%)\n",
      "Ties: 3308 (33.1%)\n",
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 3402 (34.0%)\n",
      "Player 2 wins: 3287 (32.9%)\n",
      "Ties: 3311 (33.1%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3402, 3287], 3311)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Runs\n",
    "play(s_human_like, s_random, n=10000)\n",
    "play(s_tend_to_repeat, s_tend_to_change, n=10000)\n",
    "play(s_mimic_opponent, s_random, n=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266ed36c",
   "metadata": {},
   "source": [
    "# Human like strategy against other strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97d4e5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs random\n",
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 3423 (34.2%)\n",
      "Player 2 wins: 3304 (33.0%)\n",
      "Ties: 3273 (32.7%)\n",
      "\n",
      "vs repeat variations\n",
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 3359 (33.6%)\n",
      "Player 2 wins: 3469 (34.7%)\n",
      "Ties: 3172 (31.7%)\n",
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 3202 (32.0%)\n",
      "Player 2 wins: 3291 (32.9%)\n",
      "Ties: 3507 (35.1%)\n",
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 3378 (33.8%)\n",
      "Player 2 wins: 3358 (33.6%)\n",
      "Ties: 3264 (32.6%)\n",
      "\n",
      "vs mimic opponent\n",
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 4358 (43.6%)\n",
      "Player 2 wins: 4141 (41.4%)\n",
      "Ties: 1501 (15.0%)\n",
      "\n",
      "vs human like\n",
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 3403 (34.0%)\n",
      "Player 2 wins: 3344 (33.4%)\n",
      "Ties: 3253 (32.5%)\n",
      "\n",
      "vs constants\n",
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 2937 (29.4%)\n",
      "Player 2 wins: 2216 (22.2%)\n",
      "Ties: 4847 (48.5%)\n",
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 2284 (22.8%)\n",
      "Player 2 wins: 4218 (42.2%)\n",
      "Ties: 3498 (35.0%)\n",
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 4316 (43.2%)\n",
      "Player 2 wins: 3237 (32.4%)\n",
      "Ties: 2447 (24.5%)\n",
      "\n",
      "vs result dependent\n",
      "\n",
      "--- Game Results ---\n",
      "Player 1 wins: 3641 (36.4%)\n",
      "Player 2 wins: 2833 (28.3%)\n",
      "Ties: 3526 (35.3%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3641, 2833], 3526)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# human like vs everything else:\n",
    "print(\"vs random\")\n",
    "play(s_human_like, s_random, n=10000)\n",
    "print()\n",
    "\n",
    "print(\"vs repeat variations\")\n",
    "play(s_human_like, s_never_repeat, n=10000)\n",
    "play(s_human_like, s_tend_to_repeat, n=10000)\n",
    "play(s_human_like, s_tend_to_change, n=10000)\n",
    "print()\n",
    "\n",
    "print(\"vs mimic opponent\")\n",
    "play(s_human_like, s_mimic_opponent, n = 10000)\n",
    "print()\n",
    "\n",
    "print(\"vs human like\")\n",
    "play(s_human_like, s_human_like, n = 10000)\n",
    "print()\n",
    "\n",
    "print(\"vs constants\")\n",
    "play(s_human_like, s_constant_R, n = 10000)\n",
    "play(s_human_like, s_constant_P, n = 10000)\n",
    "play(s_human_like, s_constant_S, n = 10000)\n",
    "print()\n",
    "\n",
    "print(\"vs result dependent\")\n",
    "play(s_human_like, s_result_dependent, n = 10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c128c94",
   "metadata": {},
   "source": [
    "Analyze Results of the section:\n",
    "- Against random strategies, it shows no consistent advantage, with wins, losses, and ties all close to one-third.\n",
    "- When facing reactive strategies, such as tend_to_repeat, tend_to_change, or never_repeat, outcomes remain balanced, though tie percentages fluctuate slightly.\n",
    "- Notably, when playing against s_mimic_opponent, ties drop dramatically to around 15%, even though the win/loss ratio remains roughly even, highlighting that human_like’s probabilistic bias desynchronizes mimic responses.\n",
    "- Against static constant strategies, human_like exploits its internal bias, winning decisively against constants it favors (R or S) and losing against those that counter its bias (P)\n",
    "- Finally, human_like has a moderate advantage against result-dependent strategies, suggesting that combining a biased choice distribution with minor adaptive behavior can outperform strategies that rely solely on previous outcomes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
